\chapter{Методология обучения физически-информированной нейронной сети}
С точки зрения машинного обучения и нейронных сетей есть множество важных аспектов,
помимо точности. В контексте физически-информированных нейронных сетей речь пойдет
об оптимизации архитектуры нейронной сети для ускорения обучения, увеличения точности
для оценки компонент скоростей или давления \cite{Tommaso2024pinn}.

Нейронные сети весьма непредсказуемы при обучении, особенно в случае отсутствия
обучающих и тестовых данных. Для понимания работы нейронных сетей в таком режиме
следует изучить влияние количества нейронов, активационной функции и количества слоев,
а также обратить внимание на функции активации, которые определяют,
как нейрон будет реагировать на входные данные, что может существенно влиять на способность
сети обучаться сложным функциям и обобщать полученные данные.
\section{Постановка задачи}
В основе исследуемых задач будем использовать уравнения Навье-Стокса по следующим
причинам:
\begin{enumerate}
    \item Данные уравнения используют частные производные первого и второго порядка
    \item Подразумевается система трех уравнений для двумерной задачи
    \item Наличие трех входных и трех выходных переменных для двумерной задачи
\end{enumerate}
Такой подход позволит рассмотреть физически-информированные нейронные сети на сложных,
с точки зрения модели, задачах, тем самым изучив поведение модели в нетривиальных случаях.

Для анализа будет рассмотрено течение Куэтта в силу его простоты, наличия аналитического
решения, а также наличие нулевого решение для $u_y$ и $p$, что усложняет работу нейронной
сети.
\input{images/tikz/couette_flow.tex}
Течение Куэтта представляет собой двумерный плоский канал шириной $l$, одна из стенок которого 
движется со скоростью $u_0$. Данная задача имеет аналитическое решение:
\begin{equation}
    \begin{cases}
        u_x = u_0 \frac{y}{l} \\
        u_y = 0 \\
        p = const
    \end{cases}
\end{equation}
где $y$ --- расстояние от неподвижной стенки.

\input{images/tikz/points.tex}

Используя данное аналитическое решение можно валидировать результаты нейронной сети.

Распределение точек для обучения выглядит примерно следующим образом
(рис. \ref{fig:points}) в каждый момент времени. На каждом временном шаге генерируются случайным
образом набор красных точек на границе и синих точек внутри области. Зеленые точки создаются на 
основе сетки численного (или точного) решения поставленной задачи. Такой подход позволяет использовать
синие и красные точки непосредственно для уравнений Навье-Стокса, красные точки для
граничных условий и зеленые для соответствия с точным решением, вычисленным на определенной
сетке. На такую генерацию накладываются следующие ограничения:
\begin{enumerate}
    \item Количество красных точек следует повышать, если модель отдает предпочтение уравнениям Навье-Стокса
    и игнорирует граничные условия, в результате чего получается нулевое решение.
    \item Количество синих точек следует повышать при недостаточно точном поведении жидкости внутри исследуемой
    области.
    \item Количество зеленых точек следует повышать только в случае, если модель не справляется ни прикаких
    условиях и всегда уходит в локальный минимум.
\end{enumerate}
Данные условия следует выносить в гиперпараметры для повышения качества обучения. В качестве упрощения вместо отдельных
параметров можно использовать отношение синих и красных точек в качестве первого параметра и синих и зеленых --- в 
качестве второго. 


\section{Принцип работы нейронной сети}

Искусственная нейронная сеть представляет собой последовательное преобразование
входного вектора $\mathbf{x}$ посредством набора слоёв (рис. \ref{fig:nn_structure}).
Каждый слой вычисляет взвешенную сумму входных значений с последующим применением
функции активации:

\input{images/tikz/nn_structure.tex}

$$
\mathbf{h}^{(l)} = \sigma^{(l)}\left( \mathbf{W}^{(l)} \mathbf{h}^{(l-1)} + \mathbf{b}^{(l)} \right)
$$

где $\mathbf{h}^{(0)} = \mathbf{x}$, $\mathbf{W}^{(l)}$ - матрица весов $l$-го слоя, $\mathbf{b}^{(l)}$ - смещение (bias), $\sigma^{(l)}$ - функция активации.

Обучение сети заключается в минимизации функции потерь $\mathcal{L}$ по параметрам сети $\theta = \{\mathbf{W}, \mathbf{b}\}$.


\section{Функция активации}
Каждый нейрон в нейронной сети использует функцию активации для преобразования взвешенной
суммы своих входных сигналов в выходной сигнал. Эта функция вносит нелинейность в модель,
что необходимо для обучения сложных зависимостей.

Формула, описывающая данный процесс выглядит следующим образом:

$$y = f(\sum_{i=1}^{n} w_i x_i + b)$$

где $x_i$ — $i$-й входной сигнал нейрона, $w_i$ — вес, связанный с $i$-м входным сигналом, $b$
— смещение нейрона, $f(\cdot)$ — функция активации, $y$ — выходной сигнал нейрона.

Для эффективного использования в PINNs функции активации должны удовлетворять следующим
критериям \cite{0d752c79fb816703274a3d37f85a85689a2a9405}:
\begin{itemize}
    \item функции активации должны быть гладкими и
    непрерывно дифференцируемыми, чтобы обрабатывать функции потерь, которые включают
    производные высших порядков.
    \item функции активации должны допускать неограниченные
    выходные значения, в отличие от функций $tanh$ и $sin$, которые ограничены между $-1$ и $1$.
    \item функции активации должны избегать насыщения, чтобы предотвратить
    исчезновение градиентов, что может затруднить обучение.
    \item в некоторых случаях желательно иметь контролируемое насыщение за пределами определённого
    диапазона, чтобы улучшить способность модели представлять сложные физические сигналы.
\end{itemize}


Функция активации $\sigma(x)$ определяет нелинейность слоя и влияет на способность
сети аппроксимировать сложные зависимости. В данной работе рассмотрены следующие функции
(табл. \ref{table:act_basic}).

\begin{table}[h!]
    \centering
    \caption{Основные функции активации \cite{tensorflow2015-whitepaper}}
    \renewcommand{\arraystretch}{1.5}
    \begin{tabular}{|c|c|p{7cm}|}
    \hline
    \textbf{Функция} & \textbf{Математическая формула} & \textbf{Назначение и свойства} \\
    \hline
    $\tanh$ & $\sigma(x) = \dfrac{e^{x} - e^{-x}}{e^{x} + e^{-x}}$ & Гладкая, нечётная функция с непрерывной производной. \\
    \hline
    $\sin$ & $\sigma(x) = \sin(x)$ & Используется для задач с выраженной периодичностью решения. \\
    \hline
    $\exp$ & $\sigma(x) = \exp(x)$ & Применяется для задач с экспоненциальным затуханием. \\
    \hline
    Сигмоида & $\sigma(x) = \dfrac{1}{1 + e^{-x}}$ & Гладкая функция, полезная для нормализации выходных значений. \\
    \hline
    Квадратичная & $\sigma(x) = \dfrac{1}{1 + x^2}$ & Гладкая функция с ограниченным выходом, не монотонна. \\
    \hline
    Softplus & $\sigma(x) = \log(1 + \exp(x))$ & Плавная аппроксимация ReLU, дифференцируемая и монотонная. \\
    \hline
    SiLU & $\sigma(x) = x * \sigma(x)$ & Сглаженная версия ReLU, улучшает обучение глубоких сетей. \\
    \hline
    \end{tabular}
    \label{table:act_basic}
\end{table}

\section{Оптимизаторы}
В процессе обучения нейронной сети для минимизации функции потерь $\mathcal{L}(\theta)$ по параметрам $\theta$ используются различные оптимизаторы. Ниже приведены основные из них:

\begin{itemize}
    \item \textbf{Adam}~\cite{kingma2014adam} --- адаптивный метод, основанный на оценке первых и вторых моментов градиентов. На каждой итерации параметры обновляются по правилу:
    \[
    \begin{aligned}
        m_t &= \beta_1 m_{t-1} + (1 - \beta_1) g_t \\
        v_t &= \beta_2 v_{t-1} + (1 - \beta_2) g_t^2 \\
        \hat{m}_t &= \frac{m_t}{1 - \beta_1^t} \\
        \hat{v}_t &= \frac{v_t}{1 - \beta_2^t} \\
        \theta_{t+1} &= \theta_t - \eta \frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon}
    \end{aligned}
    \]
    где $g_t$ --- градиент на шаге $t$, $\eta$ --- скорость обучения, $\beta_1$, $\beta_2$ --- параметры экспоненциального сглаживания, $\epsilon$ --- малая константа для избежания деления на ноль.

    \item \textbf{Adagrad}~\cite{duchi2011adaptive} --- оптимизатор, индивидуально адаптирующий скорость обучения для каждого параметра:
    \[
    \begin{aligned}
        G_t &= G_{t-1} + g_t^2 \\
        \theta_{t+1} &= \theta_t - \frac{\eta}{\sqrt{G_t} + \epsilon} g_t
    \end{aligned}
    \]
    где $G_t$ --- накопленная сумма квадратов градиентов.

    \item \textbf{Adamax}~\cite{kingma2014adam} --- вариант Adam, использующий норму $L_\infty$ вместо $L_2$ для второго момента:
    \[
    \begin{aligned}
        m_t &= \beta_1 m_{t-1} + (1 - \beta_1) g_t \\
        u_t &= \max(\beta_2 u_{t-1}, |g_t|) \\
        \theta_{t+1} &= \theta_t - \frac{\eta}{u_t} m_t
    \end{aligned}
    \]
    Обеспечивает устойчивость при больших градиентах.

    \item \textbf{ASGD} (Averaged Stochastic Gradient Descent)~\cite{polyak1992acceleration} --- стохастический градиентный спуск с усреднением параметров:
    \[
    \begin{aligned}
        \theta_{t+1} &= \theta_t - \eta g_t \\
        \bar{\theta}_t &= \frac{1}{t} \sum_{k=1}^{t} \theta_k
    \end{aligned}
    \]
    где $\bar{\theta}_t$ --- усреднённые параметры, что способствует лучшей сходимости и устойчивости.

    \item \textbf{RMSprop}~\cite{tieleman2012lecture} --- оптимизатор, который нормирует градиент с помощью скользящего среднего квадратов градиентов:
    \[
    \begin{aligned}
        E[g^2]_t &= \gamma E[g^2]_{t-1} + (1 - \gamma) g_t^2 \\
        \theta_{t+1} &= \theta_t - \frac{\eta}{\sqrt{E[g^2]_t} + \epsilon} g_t
    \end{aligned}
    \]
    где $\gamma$ --- коэффициент сглаживания.
\end{itemize}

\section{Процесс обучения}
Обучение проводилось с использованием фреймворка PyTorch, а также вспомогательных
библиотек и утилит tensorboard и ray tune.

Для повышения качества результатов и значительного сокращения времени вычислений и
исследований, кросс-валидация гиперпараметров модели будет проведена в два
последовательных этапа.

Вначале применяется адаптивная функция активации
REAct~\cite{0d752c79fb816703274a3d37f85a85689a2a9405}, обусловленная её вычислительной
простотой и высокой скоростью оценки значений и производных, что существенно
повышает эффективность проведения кросс-валидации. Поскольку теоретически
невозможно предсказать поведение модели при различных параметрических настройках,
кросс-валидация реализуется посредством метода перебора по сетке. В качестве
гиперпараметров рассматриваются конфигурация нейронной сети, выбор оптимизатора,
функция активации, количество точек внутри области, а также скорость обучения.


Архитектура нейронной сети исследуется с применением вариативного подхода к
подбору количества и конфигурации слоев, охватывающего как компактные структуры
(например, $16-16$ и $32-32$), так и более глубокие многослойные комбинации,
включая $32-64-32$, $64-32-64$, а также асимметричные схемы, такие как
$16-32-64$, $64-32-16$, $16-64-32$ и $64-16-32$. Особое внимание уделяется
масштабируемым конфигурациям, например $64-64$, с целью оценки влияния
вариаций числа нейронов на эффективность модели. Такой подход позволяет
систематически анализировать зависимость производительности нейронной сети
от структуры и глубины архитектуры, что является ключевым аспектом при
оптимизации моделей машинного обучения.

Для изучения влияния выбора оптимизатора на качество результатов были выбраны
следующие алгоритмы оптимизации: \textbf{Adam}, \textbf{Adagrad}, \textbf{Adamax},
а также специализированные методы \textbf{ASGD} и \textbf{RMSprop}.

Для анализа влияния параметров функции активации была выбрана группа из четырёх вариаций параметров
REAct с различными параметрическими настройками (см. рис. \ref{fig:react_func_graph}).
\input{images/tikz/react_func_graph.tex}

Обучающая выборка варьировалась между $100$ и $500$ точками для внутренней
области и неизменных $1000$ точек для граничных условий. 

Скорость обучения задавалась тремя значениями: $10^{-1}$, $10^{-2}$ и $10^{-3}$.

По итогам первого этапа исследования производится отбор наиболее эффективных результатов,
на основании которых осуществляется исключение неподходящих параметров модели.

\input{images/tikz/abu_func_graph.tex}

На втором этапе обучения используется комплексная функция активации
\textbf{ABU}~\cite{Sutfeld2018-io}, что позволяет повысить адаптивность модели за счёт
комбинирования различных активационных механизмов.

В рамках исследования, в качестве функций $\sigma_i$, входящих в уравнение \eqref{eq:abu},
используются $\mathbf{sin}$, $\mathbf{tanh}$, $\mathbf{SiLU}$, $\mathbf{quadratic}$ и
$\mathbf{softplus}$. Коэффициенты для кроссвалидации принимают значения $0$ или $1$ для всех
функций, за исключением $\mathbf{sin}$. Графическое представление данных функций приведено
на рис. \ref{fig:abu_func_graph}.
Другими словами функция активации имеет следующий вид:
\begin{equation}
    \begin{split}
        \text{ABU}(x) = \sin(x) &+ \text{Quadratic}(\beta_0 x) + \\
        &+ \text{Softplus}(\beta_1 x) + \text{SiLU}(\beta_2 x) + \tanh(\beta_3 x),
    \end{split}
    \label{eq:abu_custom}
\end{equation}
где $\beta_i$ --- коэффициент для кроссвалидации,  принимающий значения $0$ или $1$.


Для обеспечения более точной оценки результатов проводится анализ медианных значений каждого
параметра на протяжении всего периода обучения.