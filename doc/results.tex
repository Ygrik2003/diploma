\chapter{Результаты}
\begin{figure}[ht]
    \includegraphics{data/couette_react_error_best.png}
    \caption{Лучший результат в процессе кроссвалидации с функцией активации REAct}
    \label{fig:couette_react_best}
\end{figure}


В результате первого этапа обучения модель с предсказанным минимальным отклонением от
верного решения (рис. \ref{fig:couette_react_best}) имела следующие значения
гиперпараметров (табл. \ref{table:couette_react_best_params}).

\begin{table}[h!]
    \centering
    \caption{Значения гиперпараметров у модели с лучшим результатом}
    \begin{tabular}{ |c|c| } 
        \hline
        Функция активации & $\text{REAct}(0.8, -4, -3.2, 0.2)$ \\
        \hline
        Оптимизатор & Adagrad \\ 
        \hline
        Конфигурация сети & $64-16-32$ \\ 
        \hline
        Скорость обучения & $10^{-3}$ \\ 
        \hline
        Количество точек внутри области & $100$ \\ 
        \hline
    \end{tabular}
    \label{table:couette_react_best_params}
\end{table}

В результате анализа остальных моделей было подсчитано количество нулевых
решений, решений с максимальным отклонением до 20\%, а также больше 20\% и 50\%.
Помимо перечисленных также было несколько моделей, ушедших в процессе обучения в
NaN (рис. \ref{fig:couette_react_stat}). 

\begin{figure}[ht]
    \centering
    \begin{tikzpicture}
        \pgfplotstableread{
        Label   First
        NaN                     4
        Нулевое\ решение        30
        $>50\%$                 16
        $>20\%$                 94
        $<20\%$                 17
        }\datatable
        
        \begin{axis}[
            xbar stacked,
            xmin=0,
            ytick=data,
            yticklabels from table={\datatable}{Label}
            ]
            \addplot [fill=yellow] table [x=First, y expr=\coordindex] {\datatable};
        \end{axis}
    \end{tikzpicture}
    \caption{Распределение результатов кроссвалидации с функцией активации REAct}
    \label{fig:couette_react_stat}
\end{figure}

Также стоит отметить, что все нулевые решения соответствовали функции активации,
которая на всей области определения имеет отрицательные значения.

В качестве корректных параметров были отобраны те, которые соответствуют критерию
принадлежности к группе с уровнем менее 20\%. В результате, во второй этап были
включены следующие параметры:
\begin{enumerate}
    \item Конфигурации с резким переходом между слоями ($16-64-32$ и $64-16-32$) а также
    с линейным переходом ($16-32-64$ и $64-32-16$) не показали особых результатов по
    сравнению с остальными трехслойными сетями. Аналогично конфигурации
    $16-16$ и $32-32$ показали себя хуже по сравнению с $64-64$.
    \item По количеству точек внутри области значительно больше удачных
    результатов было при $100$ точек. Это поведение характеризуется 
    соотношением точек на границе и внутри области. Данное соотношение 
    показывает значимость граничных условий, что необходимо для избегания
    нулевого решения
    \item Скорость обучения влияет на то, сможет ли оптимизатор 
    выбраться из локального минимума. Лучший результат показало значение
    скорости обучения равное $10^{-3}$
    \item Среди оптимизаторов лучшие результаты показали \textbf{Adam}, \textbf{Adagrad} и
    \textbf{ASGD}, в свою очередь \textbf{Adamax} и \textbf{RSMProp} являются узкоспециализированными,
    что требует точной настройки параметров, что в данной работе не рассматривается.
\end{enumerate} 

Теперь получив более точное представление о наших параметрах можно приступить
ко второму этапу.

В представленных ниже графиках показано сравнение результатов работы нейронной сети
при различных гиперпараметрах. Такой подход позволяет детально проанализировать
влияние каждого параметра на общую эффективность модели и выявить, какие параметры
обеспечивают наилучшее качество обучения.
% \input{images/tikz/results/loss_couette_abu_neurons.tex}
% \input{images/tikz/results/loss_couette_abu_optimizer.tex}
\input{images/tikz/results/loss_couette_abu_scale_quadratic.tex}
% \input{images/tikz/results/loss_couette_abu_scale_softplus.tex}
% \input{images/tikz/results/loss_couette_abu_scale_swish.tex}
% \input{images/tikz/results/loss_couette_abu_scale_tanh.tex}

Исходя из полученых результатов можно сделать вывод, что модель со следующими
параметрами (табл. \ref{table:couette_abu_best_params}) является лучшей с точки зрения стабильности.

\begin{table}[h!]
    \centering
    \caption{Значения гиперпараметров у модели с лучшим результатом}
    \begin{tabular}{ |c|c| } 
        \hline
        Функция активации & $\text{ABU}(0, 1, 1, 1)$ \\
        \hline
        Оптимизатор & Adam \\ 
        \hline
        Конфигурация сети & $128-128$ \\ 
        \hline
    \end{tabular}
    \label{table:couette_abu_best_params}
\end{table}

\begin{figure}[ht]
    \includegraphics{data/couette_abu_error_best.png}
    \caption{Лучший результат в процессе кроссвалидации с функцией активации ABU}
    \label{fig:couette_abu_best}
\end{figure}