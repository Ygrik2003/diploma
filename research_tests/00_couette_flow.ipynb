{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from flavors.activate_function import ActivateFunctionController, ActivateFunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lx = 5.0\n",
    "Ly = 1.0\n",
    "T = 1.0\n",
    "nu = 0.01\n",
    "\n",
    "U = 1\n",
    "\n",
    "\n",
    "\n",
    "class NavierStokesModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NavierStokesModel, self).__init__()\n",
    "\n",
    "        self.activation_func = ActivateFunctionController(\n",
    "            activate_func=ActivateFunctions.AdaptiveBlendingUnit, args=dict()\n",
    "        ).get()\n",
    "\n",
    "        self.fc1 = nn.Linear(3, 32)\n",
    "        self.fc2 = nn.Linear(32, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation_func(self.fc1(x))\n",
    "        x = self.activation_func(self.fc2(x))\n",
    "        x = self.activation_func(self.fc3(x))\n",
    "        return self.fc4(x)\n",
    "\n",
    "global_epoch = 0\n",
    "writer = SummaryWriter()\n",
    "model = NavierStokesModel()\n",
    "\n",
    "\n",
    "def compute_pde(xyt):\n",
    "    global global_epoch\n",
    "    xyt.requires_grad_(True)\n",
    "    up = model(xyt)\n",
    "    u, v, p = up[:, 0], up[:, 1], up[:, 2]\n",
    "\n",
    "    u_x = torch.autograd.grad(u.sum(), xyt, create_graph=True)[0][:, 0]\n",
    "    u_y = torch.autograd.grad(u.sum(), xyt, create_graph=True)[0][:, 1]\n",
    "    u_t = torch.autograd.grad(u.sum(), xyt, create_graph=True)[0][:, 2]\n",
    "    v_x = torch.autograd.grad(v.sum(), xyt, create_graph=True)[0][:, 0]\n",
    "    v_y = torch.autograd.grad(v.sum(), xyt, create_graph=True)[0][:, 1]\n",
    "    v_t = torch.autograd.grad(v.sum(), xyt, create_graph=True)[0][:, 2]\n",
    "    p_x = torch.autograd.grad(p.sum(), xyt, create_graph=True)[0][:, 0]\n",
    "    p_y = torch.autograd.grad(p.sum(), xyt, create_graph=True)[0][:, 1]\n",
    "\n",
    "    u_xx = torch.autograd.grad(u_x.sum(), xyt, create_graph=True)[0][:, 0]\n",
    "    u_yy = torch.autograd.grad(u_y.sum(), xyt, create_graph=True)[0][:, 1]\n",
    "    v_xx = torch.autograd.grad(v_x.sum(), xyt, create_graph=True)[0][:, 0]\n",
    "    v_yy = torch.autograd.grad(v_y.sum(), xyt, create_graph=True)[0][:, 1]\n",
    "\n",
    "    continuity = u_x + v_y\n",
    "\n",
    "    momentum_x = u_t + u * u_x + v * u_y + p_x - nu * (u_xx + u_yy)\n",
    "    momentum_y = v_t + u * v_x + v * v_y + p_y - nu * (v_xx + v_yy)\n",
    "\n",
    "\n",
    "    writer.add_scalar(\"pde/continuity\", torch.abs(torch.mean(continuity)), global_epoch)\n",
    "    writer.add_scalar(\"pde/momentum_x\", torch.abs(torch.mean(momentum_x)), global_epoch)\n",
    "    writer.add_scalar(\"pde/momentum_y\", torch.abs(torch.mean(momentum_y)), global_epoch)\n",
    "\n",
    "    return continuity, momentum_x, momentum_y\n",
    "\n",
    "\n",
    "def boundary_conditions():\n",
    "    num_points = 1000\n",
    "    t = T * np.random.random(num_points)\n",
    "    bottom_bc = torch.tensor(\n",
    "        np.stack(\n",
    "            [np.random.uniform(0, Lx, num_points), np.zeros(num_points), t], axis=-1\n",
    "        ),\n",
    "        requires_grad=False,\n",
    "    ).float()\n",
    "    left_bc = torch.tensor(\n",
    "        np.stack(\n",
    "            [np.zeros(num_points), np.random.uniform(0, Ly, num_points), t], axis=-1\n",
    "        ),\n",
    "        requires_grad=False,\n",
    "    ).float()\n",
    "    top_bc = torch.tensor(\n",
    "        np.stack(\n",
    "            [np.random.uniform(0, Lx, num_points), np.full(num_points, Ly), t], axis=-1\n",
    "        ),\n",
    "        requires_grad=False,\n",
    "    ).float()\n",
    "    right_bc = torch.tensor(\n",
    "        np.stack(\n",
    "            [np.full(num_points, Lx), np.random.uniform(0, Ly, num_points), t], axis=-1\n",
    "        ),\n",
    "        requires_grad=False,\n",
    "    ).float()\n",
    "\n",
    "    bottom_predict = model(bottom_bc)\n",
    "    left_predict = model(left_bc)\n",
    "    top_predict = model(top_bc)\n",
    "    right_predict = model(right_bc)\n",
    "\n",
    "    u, v, p = left_predict[:, 0], left_predict[:, 1], left_predict[:, 2]\n",
    "    left_loss = torch.mean(p**2)\n",
    "    u, v, p = top_predict[:, 0], top_predict[:, 1], top_predict[:, 2]\n",
    "    top_loss = torch.mean((u - U)**2 + v**2)\n",
    "    u, v, p = bottom_predict[:, 0], bottom_predict[:, 1], bottom_predict[:, 2]\n",
    "    bottom_loss = torch.mean(u**2 + v**2)\n",
    "    u, v, p = right_predict[:, 0], right_predict[:, 1], right_predict[:, 2]\n",
    "    right_loss = torch.mean(p**2)\n",
    "\n",
    "    writer.add_scalar(\"bc/bottom\", torch.mean(bottom_loss), global_epoch)\n",
    "    writer.add_scalar(\"bc/left\", torch.mean(left_loss), global_epoch)\n",
    "    writer.add_scalar(\"bc/right\", torch.mean(right_loss), global_epoch)\n",
    "    writer.add_scalar(\"bc/top\", torch.mean(top_loss), global_epoch)\n",
    "\n",
    "    return right_loss + bottom_loss + top_loss +left_loss\n",
    "\n",
    "\n",
    "def generate_data(num_points):\n",
    "    x = np.random.uniform(0, Lx, num_points)\n",
    "    y = np.random.uniform(0, Ly, num_points)\n",
    "    t = np.random.uniform(0, T, num_points)\n",
    "    xyt = np.stack([x, y, t], axis=-1)\n",
    "    return torch.tensor(xyt, requires_grad=True).float()\n",
    "\n",
    "\n",
    "def loss_function(xyt):\n",
    "    continuity, momentum_x, momentum_y = compute_pde(xyt)\n",
    "    pde_loss = (\n",
    "        torch.mean(continuity**2)\n",
    "        + torch.mean(momentum_x**2)\n",
    "        + torch.mean(momentum_y**2)\n",
    "    )\n",
    "    bc_loss = boundary_conditions()\n",
    "    total_loss = pde_loss + bc_loss\n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.8351815342903137\n",
      "Epoch 100, Loss: 0.002486208453774452\n",
      "Epoch 200, Loss: 0.0007067625410854816\n",
      "Epoch 300, Loss: 0.0003842358128167689\n",
      "Epoch 400, Loss: 0.00026178581174463034\n",
      "Epoch 500, Loss: 0.00017383205704391003\n",
      "Epoch 600, Loss: 0.00013504951493814588\n",
      "Epoch 700, Loss: 0.00010665427544154227\n",
      "Epoch 800, Loss: 8.65926340338774e-05\n",
      "Epoch 900, Loss: 7.070029823808e-05\n",
      "Epoch 1000, Loss: 5.734114529332146e-05\n",
      "Epoch 1100, Loss: 4.844922659685835e-05\n",
      "Epoch 1200, Loss: 3.54194053215906e-05\n",
      "Epoch 1300, Loss: 3.278957592556253e-05\n",
      "Epoch 1400, Loss: 2.9494805858121254e-05\n",
      "Epoch 1500, Loss: 2.367371052969247e-05\n",
      "Epoch 1600, Loss: 2.0498016965575516e-05\n",
      "Epoch 1700, Loss: 1.7124937585322186e-05\n",
      "Epoch 1800, Loss: 3.87069521821104e-05\n",
      "Epoch 1900, Loss: 1.5494399121962488e-05\n",
      "Epoch 2000, Loss: 1.1533819815667812e-05\n",
      "Epoch 2100, Loss: 1.0844717508007307e-05\n",
      "Epoch 2200, Loss: 1.1725364856829401e-05\n",
      "Epoch 2300, Loss: 1.8627280951477587e-05\n",
      "Epoch 2400, Loss: 8.728684406378306e-06\n",
      "Epoch 2500, Loss: 9.443884664506186e-06\n",
      "Epoch 2600, Loss: 1.975156192202121e-05\n",
      "Epoch 2700, Loss: 8.410783266299404e-06\n",
      "Epoch 2800, Loss: 1.3787343050353229e-05\n",
      "Epoch 2900, Loss: 8.930093827075325e-06\n",
      "Epoch 3000, Loss: 2.5098715923377313e-05\n",
      "Epoch 3100, Loss: 6.57148575555766e-06\n",
      "Epoch 3200, Loss: 2.1002848370699212e-05\n",
      "Epoch 3300, Loss: 5.749728188675363e-06\n",
      "Epoch 3400, Loss: 5.908421371714212e-06\n",
      "Epoch 3500, Loss: 1.494937350798864e-05\n",
      "Epoch 3600, Loss: 7.985470801941119e-06\n",
      "Epoch 3700, Loss: 6.426501386158634e-06\n",
      "Epoch 3800, Loss: 4.601110504154349e-06\n",
      "Epoch 3900, Loss: 4.611840267898515e-06\n",
      "Epoch 4000, Loss: 4.630709736375138e-05\n",
      "Epoch 4100, Loss: 0.00011927934974664822\n",
      "Epoch 4200, Loss: 0.00021870830096304417\n",
      "Epoch 4300, Loss: 8.511328815075103e-06\n",
      "Epoch 4400, Loss: 5.770307325292379e-06\n",
      "Epoch 4500, Loss: 2.385375955782365e-05\n",
      "Epoch 4600, Loss: 2.576850965851918e-05\n",
      "Epoch 4700, Loss: 8.866309144650586e-06\n",
      "Epoch 4800, Loss: 1.6959431377472356e-05\n",
      "Epoch 4900, Loss: 4.506345248955768e-06\n",
      "Epoch 5000, Loss: 8.38933283375809e-06\n",
      "Epoch 5100, Loss: 0.00015263828390743583\n",
      "Epoch 5200, Loss: 1.8714312318479642e-05\n",
      "Epoch 5300, Loss: 2.345717257412616e-05\n",
      "Epoch 5400, Loss: 3.5312959880684502e-06\n",
      "Epoch 5500, Loss: 4.445779723027954e-06\n",
      "Epoch 5600, Loss: 2.1194589862716384e-05\n",
      "Epoch 5700, Loss: 5.939949187450111e-05\n",
      "Epoch 5800, Loss: 0.0002755200839601457\n",
      "Epoch 5900, Loss: 5.5973900998651516e-06\n",
      "Epoch 6000, Loss: 4.939310656482121e-06\n",
      "Epoch 6100, Loss: 8.815151886665262e-06\n",
      "Epoch 6200, Loss: 7.871452908148058e-06\n",
      "Epoch 6300, Loss: 8.098099897324573e-06\n",
      "Epoch 6400, Loss: 3.2668685889802873e-06\n",
      "Epoch 6500, Loss: 5.896164111618418e-06\n",
      "Epoch 6600, Loss: 5.713035534427036e-06\n",
      "Epoch 6700, Loss: 5.050709205534076e-06\n",
      "Epoch 6800, Loss: 5.236042488832027e-05\n",
      "Epoch 6900, Loss: 2.7564558422454866e-06\n",
      "Epoch 7000, Loss: 4.545406227407511e-06\n",
      "Epoch 7100, Loss: 4.795126642420655e-06\n",
      "Epoch 7200, Loss: 7.517824997194111e-06\n",
      "Epoch 7300, Loss: 7.11925167706795e-05\n",
      "Epoch 7400, Loss: 0.00016759373829700053\n",
      "Epoch 7500, Loss: 3.200886112608714e-06\n",
      "Epoch 7600, Loss: 2.784570460789837e-05\n",
      "Epoch 7700, Loss: 3.569916316337185e-06\n",
      "Epoch 7800, Loss: 6.309629497991409e-06\n",
      "Epoch 7900, Loss: 2.4526256311219186e-05\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "num_epochs = 8000\n",
    "num_points = 500\n",
    "for epoch in range(num_epochs):\n",
    "    global_epoch += 1\n",
    "    xyt = generate_data(num_points)\n",
    "    optimizer.zero_grad()\n",
    "    loss = loss_function(xyt)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "\n",
    "print(\"Training completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_flow_data(model, writer: SummaryWriter):\n",
    "    nx, ny, nt = 50, 50, 4\n",
    "    x = np.linspace(0, Lx, nx)\n",
    "    y = np.linspace(0, Ly, ny)\n",
    "    t = np.linspace(0, T, nt)\n",
    "    X, Y, t_grid = np.meshgrid(x, y, t)\n",
    "    XYT = np.stack([X.flatten(), Y.flatten(), t_grid.flatten()], axis=-1)\n",
    "    XYT_tensor = torch.tensor(XYT, requires_grad=False).float()\n",
    "\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    with torch.no_grad():\n",
    "        predictions = model(XYT_tensor).cpu().numpy()\n",
    "\n",
    "    U_calc = predictions[:, 0].reshape((ny, nx, nt))\n",
    "    V_calc = predictions[:, 1].reshape((ny, nx, nt))\n",
    "    # P_calc = predictions[:, 2].reshape((ny, nx, nt))\n",
    "\n",
    "    U_exact = np.tile(U / Ly * y, (nx)).reshape(nx, ny).T\n",
    "    V_exact = 0 * y[None, :] * x[:, None]\n",
    "\n",
    "    U_error = np.abs(U_exact - U_calc[:, :, 0])\n",
    "    V_error = np.abs(V_exact - V_calc[:, :, 0])\n",
    "\n",
    "    error = np.sqrt(U_error**2 + V_error**2)\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    ax = fig.add_subplot(111)\n",
    "    c3 = ax.contourf(X, Y, error, levels=50, cmap=\"viridis\")\n",
    "    ax.set_title(\"Error\")\n",
    "    fig.colorbar(c3)\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    writer.add_figure(\"total/error\", figure=fig, global_step=global_epoch)\n",
    "\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_flow_data(model, writer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
