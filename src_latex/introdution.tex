% \chapter{Введение}

% \section{Физически-информированные нейронные сети}
% Физически-информированные нейронные сети (Physical-Informed Neural Network, PINN), 
% также называемые нейронными сетями, обученными теории (Theory-Trained Neural Networks)
% --- разновидность нейронных сетей, адаптированных для решения дифференциальных
% уравнений и их систем.


% Такие сети представляют собой тип универсальных аппроксиматоров функций, которые могут внедрять информацию
% о любых физических законах, управляющих данным набором данных, в процесс обучения, 
% и могут быть описаны с помощью дифференциальных уравнений в частных производных. 
% Они позволяют преодолеть низкую доступность данных в некоторых биологических и инженерных системах, 
% однако большинству современных методов машинного обучения недостает надежности,
% что делает их неэффективными в таких сценариях. Предварительное знание общих физических законов 
% действует при обучении нейронных сетей как средство регуляризации, которое ограничивает 
% пространство допустимых решений, повышая корректность аппроксимации функции. Таким образом, 
% внедрение этой предварительной информации в нейронную сеть приводит к повышению информативности
% имеющихся данных, облегчая алгоритму обучения поиск правильного решения и хорошее обобщение
% даже при небольшом количестве обучающих примеров.

% Большинство физических законов, управляющих динамикой системы, могут быть описаны с помощью
% дифференциальных уравнений в частных производных. Например, уравнения Навье–Стокса представляют 
% собой набор дифференциальных уравнений в частных производных, полученных на основе законов сохранения,
% которые управляют механикой жидкости и газа. Решение уравнений Навье–Стокса с соответствующими начальными
% и граничными условиями позволяет количественно оценить динамику потока в условиях точно определенной геометрии.
% Однако эти уравнения не могут быть решены точно, и поэтому необходимо использовать численные методы.
% В этой ситуации эти основные уравнения должны быть решены с учетом предыдущих допущений, линеаризации и адекватной
% дискретизации во времени и пространстве.

% В последнее время решение управляющих уравнений физических явлений в частных производных с использованием глубокого обучения
% стало новой областью научного машинного обучения (SciML), использующей теорему универсальной аппроксимации и высокую
% выразительность нейронных сетей. В общем, глубокие нейронные сети могут аппроксимировать любую многомерную функцию
% при условии наличия достаточного количества обучающих данных. Однако такие сети не учитывают физические характеристики,
% лежащие в основе задачи, и уровень точности аппроксимации, обеспечиваемый ими, по-прежнему сильно зависит от тщательного
% определения геометрии задачи, а также начальных и граничных условий. Без этой предварительной информации решение не будет
% уникальным и может потерять физическую корректность. С другой стороны, физически-информированные нейронные сети используют
% управляющие физические уравнения при обучении нейронных сетей. А именно, PINN предназначены для обучения в соответствии
% с заданными данными обучения, а также введенными управляющими уравнениями. Таким образом, нейронная сеть может
% руководствоваться обучающими данными, которые не обязательно должны быть большими и полными. Таким образом, при наличии
% определенных знаний о физических характеристиках задачи и некоторой форме обучающих данных (даже редких и неполных)
% PINN может быть использован для поиска оптимального решения с высокой точностью. (нужен источник)

% PINN позволяют решать широкий спектр задач в области вычислительной техники и представляют собой новаторскую технологию,
% ведущую к разработке новых классов численных методов для уравнений в частных производных. PINNs можно рассматривать как безсеточную альтернативу
% традиционным подходам (например, CFD для гидродинамики) и новым подходам, основанным на данных, для инверсии модели
% и идентификации системы. Примечательно, что обученная сеть PINN может использоваться для прогнозирования значений на
% имитационных сетках различного разрешения без необходимости переобучения. Кроме того, они позволяют использовать
% автоматическое дифференцирование для вычисления требуемых производных в уравнениях с частными производными. Новый класс
% методов дифференцирования, широко используемых для создания нейронных сетей, по оценкам, превосходит численное или символьное
% дифференцирование. (нужен источник)

% \section{Проблема метода}
% Данный подход универсален для задач, решение которых гладкое и непрерывное во всей области решения. Для решений, содержащих
% разрывы, обычная модель будет выдавать значительную погрешность даже для большой модели с длительным обучением. Связано это с тем,
% что стандартные функции активации зачастую гладкие или непрерывные, что не позволяет нейронной сети нарушить гладкость
% результирующего решения. В таких случаях необходимо вводить новые активационные функции, либо использовать существующие,
% которые будут специфичны для конкретной задачи. Таким образом, для сложных задач следует использовать как минимум ReLU
% функцию активации в силу ее не гладкости(?). Далее в работе будет подробно описано влияение функции активации, количество слоев,
% нейронов и количество эпох на результат для наглядного изображения проблемы для случаев гладкого и негладкого(?) решения.

% % \section{Универсальная теорема об аппроксимации}
% % \section{Теорема Колмогорова-Арнольда}

% \section{Методы исследования}
% Че нибудь про технологии